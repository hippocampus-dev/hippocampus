{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Injection Detection Model\n",
    "\n",
    "This notebook builds a machine learning model to detect SQL injection attacks using LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:25.119826Z",
     "start_time": "2025-09-06T09:04:25.117956Z"
    }
   },
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import re\n",
    "import math\n",
    "import collections\n",
    "import lightgbm\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "import joblib\n",
    "import optuna"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Constants"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:25.166242Z",
     "start_time": "2025-09-06T09:04:25.164310Z"
    }
   },
   "source": [
    "RANDOM_STATE = 42\n",
    "MAX_QUERY_LENGTH = 2000\n",
    "\n",
    "MALICIOUS_PATTERNS = [\n",
    "    (r'\\bor\\b.*?=.*?\\bor\\b', 3),\n",
    "    (r'\\bunion\\b.*?\\bselect\\b', 5),\n",
    "    (r'\\bdrop\\b.*?\\btable\\b', 5),\n",
    "    (r'--', 2),\n",
    "    (r'/\\*.*?\\*/', 2),\n",
    "    (r'\\bexec\\b.*?\\bxp_', 4),\n",
    "    (r'\\bsleep\\b\\s*\\(', 3),\n",
    "    (r'\\bwaitfor\\b.*?\\bdelay\\b', 3),\n",
    "    (r'\\bconcat\\b\\s*\\(', 2),\n",
    "    (r'\\bchar\\b\\s*\\(', 2),\n",
    "    (r'@@version', 3),\n",
    "    (r'\\bsubstring\\b\\s*\\(', 2)\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:25.219300Z",
     "start_time": "2025-09-06T09:04:25.216609Z"
    }
   },
   "source": "def get_device_params():\n    try:\n        lightgbm.train(\n            {'device': 'gpu', 'objective': 'regression', 'verbose': -1},\n            lightgbm.Dataset([[1]], label=[0]),\n            num_boost_round=1\n        )\n        return {'device': 'gpu'}\n    except Exception:\n        return {'device': 'cpu', 'num_threads': 0}\n\nDEVICE_PARAMS = get_device_params()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:25.266397Z",
     "start_time": "2025-09-06T09:04:25.264424Z"
    }
   },
   "source": [
    "def calculate_entropy(text):\n",
    "    if not text:\n",
    "        return 0\n",
    "    character_frequency = collections.Counter(text)\n",
    "    text_length = len(text)\n",
    "    entropy = 0\n",
    "    for count in character_frequency.values():\n",
    "        probability = count / text_length\n",
    "        if probability > 0:\n",
    "            entropy -= probability * math.log2(probability)\n",
    "    return entropy"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:25.314609Z",
     "start_time": "2025-09-06T09:04:25.311231Z"
    }
   },
   "source": [
    "def extract_features(query):\n",
    "    if not query or not isinstance(query, str):\n",
    "        return {}\n",
    "\n",
    "    query = query[:MAX_QUERY_LENGTH]\n",
    "    query_lower = query.lower()\n",
    "    query_length = len(query)\n",
    "\n",
    "    special_char_count = len(re.findall(r'[^a-zA-Z0-9\\s]', query))\n",
    "\n",
    "    sql_keywords = ['select', 'from', 'where', 'union', 'drop', 'insert', 'update', 'delete']\n",
    "    sql_keyword_count = sum(1 for keyword in sql_keywords if keyword in query_lower)\n",
    "\n",
    "    entropy = calculate_entropy(query)\n",
    "    single_quote_count = query.count(\"'\")\n",
    "    double_quote_count = query.count('\"')\n",
    "    has_comment = 1 if '--' in query or '/*' in query or '*/' in query else 0\n",
    "    has_union = 1 if 'union' in query_lower else 0\n",
    "    parentheses_count = query.count('(') + query.count(')')\n",
    "    semicolon_count = query.count(';')\n",
    "\n",
    "    whitespace_count = sum(1 for character in query if character.isspace())\n",
    "    whitespace_ratio = whitespace_count / max(query_length, 1)\n",
    "    numeric_count = sum(1 for character in query if character.isdigit())\n",
    "\n",
    "    malicious_pattern_score = 0\n",
    "    for pattern, weight in MALICIOUS_PATTERNS:\n",
    "        if re.search(pattern, query_lower, re.IGNORECASE):\n",
    "            malicious_pattern_score += weight\n",
    "\n",
    "    return {\n",
    "        'query_length': query_length,\n",
    "        'special_char_count': special_char_count,\n",
    "        'sql_keyword_count': sql_keyword_count,\n",
    "        'entropy': entropy,\n",
    "        'single_quote_count': single_quote_count,\n",
    "        'double_quote_count': double_quote_count,\n",
    "        'has_comment': has_comment,\n",
    "        'has_union': has_union,\n",
    "        'parentheses_count': parentheses_count,\n",
    "        'semicolon_count': semicolon_count,\n",
    "        'whitespace_ratio': whitespace_ratio,\n",
    "        'numeric_count': numeric_count,\n",
    "        'malicious_pattern_score': malicious_pattern_score\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:25.361991Z",
     "start_time": "2025-09-06T09:04:25.359577Z"
    }
   },
   "source": [
    "def generate_synthetic_malicious_queries(count):\n",
    "    templates = [\n",
    "        \"' OR '1'='1\",\n",
    "        \"' OR '1'='1' --\",\n",
    "        \"' OR '1'='1' /*\",\n",
    "        \"admin' --\",\n",
    "        \"admin' #\",\n",
    "        \"admin'/*\",\n",
    "        \"' or 1=1--\",\n",
    "        \"' or 1=1#\",\n",
    "        \"' or 1=1/*\",\n",
    "        \"') or '1'='1--\",\n",
    "        \"') or ('1'='1--\",\n",
    "        \"'; exec xp_cmdshell('dir'); --\",\n",
    "        \"'; DROP TABLE users; --\",\n",
    "        \"1' UNION SELECT NULL--\",\n",
    "        \"' UNION SELECT username, password FROM users--\",\n",
    "        \"1' AND 1=1--\",\n",
    "        \"1' AND 1=2--\",\n",
    "        \"' OR EXISTS(SELECT * FROM users WHERE username='admin'\",\n",
    "        \"' OR 1=1 LIMIT 1--\",\n",
    "        \"' OR 'a'='a\",\n",
    "        \"') OR ('a'='a\",\n",
    "        '\"; DROP TABLE users; --',\n",
    "        \"' OR SLEEP(5)--\",\n",
    "        \"' OR 1=1; WAITFOR DELAY '00:00:05'--\",\n",
    "        \"' UNION ALL SELECT @@version--\",\n",
    "        \"' AND ASCII(SUBSTRING((SELECT password FROM users LIMIT 1),1,1)) > 64--\"\n",
    "    ]\n",
    "    queries = []\n",
    "    for i in range(count):\n",
    "        template = templates[i % len(templates)]\n",
    "        variation = template.replace('1', str(i % 10))\n",
    "        queries.append(variation)\n",
    "    return queries"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T03:02:28.369409Z",
     "start_time": "2025-09-05T03:02:28.367841Z"
    }
   },
   "source": [
    "## 5. Load External Dataset (SQLiV3)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:25.446147Z",
     "start_time": "2025-09-06T09:04:25.407554Z"
    }
   },
   "source": "import os\n\nif not os.path.exists('sqliv5-dataset'):\n    os.system('git clone https://github.com/nidnogg/sqliv5-dataset.git')\n\ndataset_path = 'sqliv5-dataset/SQLiV3.csv'\ndata_raw = pandas.read_csv(dataset_path, header=None, encoding='utf-8', on_bad_lines='skip')\ndata_raw.columns = ['Query', 'Label', 'Col3', 'Col4']\n\ndata = data_raw[['Query', 'Label']].copy()\ndata['Label'] = pandas.to_numeric(data['Label'], errors='coerce')\ndata = data[data['Label'].isin([0, 1])]\ndata = data[data['Query'].notna()]\ndata = data[data['Query'].str.len() > 0]\ndata['Label'] = data['Label'].astype(int)\n\nprint(f\"Dataset size: {len(data)}\")\nprint(f\"Malicious: {sum(data['Label'] == 1)}, Benign: {sum(data['Label'] == 0)}\")\nprint(f\"Balance ratio: {sum(data['Label'] == 1) / len(data):.2%}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Extraction and Data Splitting (External Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:25.962714Z",
     "start_time": "2025-09-06T09:04:25.462054Z"
    }
   },
   "source": "features_list = []\nfor query in data['Query']:\n    features_list.append(extract_features(query))\n\nX = pandas.DataFrame(features_list)\ny = data['Label'].reset_index(drop=True)\nX = X.fillna(0)\n\nscaler = sklearn.preprocessing.StandardScaler()\nX_normalized = scaler.fit_transform(X)\nX_normalized = pandas.DataFrame(X_normalized, columns=X.columns)\n\n# Use 80/20 split only for hyperparameter tuning\nX_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(\n    X_normalized, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n\nprint(f\"Dataset shape: {X.shape}\")\nprint(f\"Train: {X_train.shape[0]}, Val: {X_val.shape[0]}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:25.991127Z",
     "start_time": "2025-09-06T09:04:25.987160Z"
    }
   },
   "source": [
    "def optimize_hyperparameters(X_train, y_train, X_val, y_val, n_trials=50):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 60),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.2, log=True),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 0.95),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 0.95),\n",
    "            'bagging_frequency': trial.suggest_int('bagging_frequency', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 10, 40),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-6, 1.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-6, 1.0, log=True),\n",
    "            'verbose': -1,\n",
    "            'random_state': RANDOM_STATE\n",
    "        }\n",
    "\n",
    "        train_data = lightgbm.Dataset(X_train, label=y_train)\n",
    "        valid_data = lightgbm.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "        model = lightgbm.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[valid_data],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[\n",
    "                lightgbm.early_stopping(50),\n",
    "                lightgbm.log_evaluation(0)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        y_pred_proba = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        auc_score = sklearn.metrics.roc_auc_score(y_val, y_pred_proba)\n",
    "\n",
    "        trial.report(auc_score, model.best_iteration)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        return auc_score\n",
    "\n",
    "    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=4, show_progress_bar=True)\n",
    "\n",
    "    print(f\"Best AUC-ROC: {study.best_value:.4f}\")\n",
    "    return study.best_params"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:34.185951Z",
     "start_time": "2025-09-06T09:04:26.037394Z"
    }
   },
   "source": "best_params = optimize_hyperparameters(X_train, y_train, X_val, y_val, n_trials=20)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Train Final Model"
  },
  {
   "cell_type": "code",
   "source": "lgb_params = {\n    'objective': 'binary',\n    'metric': 'binary_logloss',\n    'boosting_type': 'gbdt',\n    'verbose': -1,\n    'random_state': RANDOM_STATE,\n    **best_params\n}\n\ntrain_data = lightgbm.Dataset(X_train, label=y_train)\nvalid_data = lightgbm.Dataset(X_val, label=y_val, reference=train_data)\n\nmodel = lightgbm.train(\n    lgb_params,\n    train_data,\n    valid_sets=[valid_data],\n    num_boost_round=1000,\n    callbacks=[\n        lightgbm.early_stopping(50),\n        lightgbm.log_evaluation(100)\n    ]\n)\n\nprint(f\"Best iteration: {model.best_iteration}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:34.629704Z",
     "start_time": "2025-09-06T09:04:34.248963Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Model Evaluation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def evaluate_with_cross_validation(params, X, y, n_folds=5):\n    \"\"\"Evaluate model using cross-validation only\"\"\"\n    kfold = sklearn.model_selection.StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_STATE)\n    cv_scores = []\n    \n    for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n        X_train_cv = X.iloc[train_idx]\n        y_train_cv = y.iloc[train_idx]\n        X_val_cv = X.iloc[val_idx]\n        y_val_cv = y.iloc[val_idx]\n        \n        train_data = lightgbm.Dataset(X_train_cv, label=y_train_cv)\n        valid_data = lightgbm.Dataset(X_val_cv, label=y_val_cv, reference=train_data)\n        \n        model_cv = lightgbm.train(\n            params,\n            train_data,\n            valid_sets=[valid_data],\n            num_boost_round=1000,\n            callbacks=[\n                lightgbm.early_stopping(50),\n                lightgbm.log_evaluation(0)\n            ]\n        )\n        \n        y_pred_proba = model_cv.predict(X_val_cv, num_iteration=model_cv.best_iteration)\n        auc_score = sklearn.metrics.roc_auc_score(y_val_cv, y_pred_proba)\n        cv_scores.append(auc_score)\n        print(f\"Fold {fold + 1}: AUC-ROC = {auc_score:.4f}\")\n    \n    print(f\"\\nOverall: {numpy.mean(cv_scores):.4f} Â± {numpy.std(cv_scores):.4f}\")\n    return cv_scores",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:34.642146Z",
     "start_time": "2025-09-06T09:04:34.638850Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# For deployment, use the final model trained on validation data\n# For evaluation, use cross-validation\nprint(\"\\nCross-Validation Evaluation:\")\ncv_scores = evaluate_with_cross_validation(lgb_params, X_normalized, y)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:35.461261Z",
     "start_time": "2025-09-06T09:04:35.280830Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Find optimal threshold using the trained model\nX_val_pred = model.predict(X_val, num_iteration=model.best_iteration)\nthresholds = numpy.linspace(0, 1, 100)\nf1_scores = []\n\nfor threshold in thresholds:\n    y_pred = (X_val_pred > threshold).astype(int)\n    if sum(y_pred) > 0:\n        f1 = sklearn.metrics.f1_score(y_val, y_pred)\n        f1_scores.append(f1)\n    else:\n        f1_scores.append(0)\n\noptimal_threshold = thresholds[numpy.argmax(f1_scores)]\nprint(f\"Optimal threshold: {optimal_threshold:.3f}\")"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "outputs": [],
   "execution_count": null,
   "source": "## 10. Model Persistence"
  },
  {
   "cell_type": "code",
   "source": "def save_model(model, scaler, feature_names, filepath):\n    model_data = {\n        'model': model,\n        'scaler': scaler,\n        'feature_names': feature_names,\n        'optimal_threshold': optimal_threshold,\n        'model_params': lgb_params\n    }\n    joblib.dump(model_data, filepath)\n    print(f\"Model saved to {filepath}\")\n\ndef predict_query(query, model_data):\n    features = extract_features(query)\n    feature_df = pandas.DataFrame([features])\n\n    missing_features = set(model_data['feature_names']) - set(feature_df.columns)\n    for feature in missing_features:\n        feature_df[feature] = 0\n\n    feature_df = feature_df[model_data['feature_names']]\n    features_normalized = model_data['scaler'].transform(feature_df)\n    probability = model_data['model'].predict(features_normalized, num_iteration=model_data['model'].best_iteration)[0]\n    prediction = \"MALICIOUS\" if probability > model_data['optimal_threshold'] else \"BENIGN\"\n\n    return {\n        'query': query,\n        'prediction': prediction,\n        'probability': probability,\n        'threshold': model_data['optimal_threshold']\n    }\n\n# Save the trained model\nscaler = sklearn.preprocessing.StandardScaler()\nscaler.fit(X)\nsave_model(model, scaler, list(X.columns), '/tmp/sql_injection_model.pkl')\n\n# Feature importance\nfeature_importance = pandas.DataFrame({\n    'feature': X.columns,\n    'importance': model.feature_importance(importance_type='gain')\n}).sort_values('importance', ascending=False)\n\nprint(\"\\\\nTop 5 Most Important Features:\")\nprint(feature_importance.head(5).to_string(index=False))",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 11. Testing with Sample Queries",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "test_queries = [\n    \"SELECT * FROM users WHERE id = 123\",\n    \"' OR 1=1 --\",\n    \"admin'; DROP TABLE users; --\",\n    \"1' UNION SELECT username, password FROM admin_users--\",\n    \"'; exec xp_cmdshell 'net user hacker password123 /add' --\",\n    \"' OR SLEEP(5)--\",\n]\n\nfor query in test_queries:\n    result = predict_query(query, {'model': model, 'scaler': scaler,\n                                   'feature_names': list(X.columns),\n                                   'optimal_threshold': optimal_threshold})\n    print(f\"{query[:50]:50} -> {result['prediction']:10} ({result['probability']:.3f})\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:04:38.543857Z",
     "start_time": "2025-09-06T09:04:38.470818Z"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}